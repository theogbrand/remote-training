{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fcb4693-4bad-4931-a11b-ad86b4db5eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "# must download when new kernel created\n",
    "!pip install git+https://github.com/huggingface/transformers -qqq\n",
    "!pip install datasets -qqq\n",
    "!pip install bitsandbytes -qqq\n",
    "!pip install huggingface_hub -qqq\n",
    "!pip install peft -qqq\n",
    "!pip install accelerate -qqq\n",
    "!pip install bitsandbytes -qqq\n",
    "!pip install trl -qqq\n",
    "!pip install wandb -qqq\n",
    "!pip install ipywidgets -qqq\n",
    "!pip install -U \"huggingface_hub[cli]\" -qqq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "265d704e-cb0b-4335-808f-04810a14736b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                   Version\n",
      "------------------------- ---------------\n",
      "accelerate                0.26.1\n",
      "aiohttp                   3.9.1\n",
      "aiosignal                 1.3.1\n",
      "anyio                     4.2.0\n",
      "appdirs                   1.4.4\n",
      "argon2-cffi               23.1.0\n",
      "argon2-cffi-bindings      21.2.0\n",
      "arrow                     1.3.0\n",
      "asttokens                 2.4.1\n",
      "async-lru                 2.0.4\n",
      "async-timeout             4.0.3\n",
      "attrs                     23.2.0\n",
      "Babel                     2.14.0\n",
      "beautifulsoup4            4.12.2\n",
      "bitsandbytes              0.42.0\n",
      "bleach                    6.1.0\n",
      "certifi                   2023.11.17\n",
      "cffi                      1.16.0\n",
      "charset-normalizer        3.3.2\n",
      "click                     8.1.7\n",
      "comm                      0.2.1\n",
      "datasets                  2.16.1\n",
      "debugpy                   1.8.0\n",
      "decorator                 5.1.1\n",
      "defusedxml                0.7.1\n",
      "dill                      0.3.7\n",
      "docker-pycreds            0.4.0\n",
      "docstring-parser          0.15\n",
      "exceptiongroup            1.2.0\n",
      "executing                 2.0.1\n",
      "fastjsonschema            2.19.1\n",
      "filelock                  3.13.1\n",
      "fqdn                      1.5.1\n",
      "frozenlist                1.4.1\n",
      "fsspec                    2023.10.0\n",
      "gitdb                     4.0.11\n",
      "GitPython                 3.1.41\n",
      "huggingface-hub           0.20.2\n",
      "idna                      3.6\n",
      "inquirerpy                0.3.4\n",
      "ipykernel                 6.28.0\n",
      "ipython                   8.20.0\n",
      "ipywidgets                8.1.1\n",
      "isoduration               20.11.0\n",
      "jedi                      0.19.1\n",
      "Jinja2                    3.1.3\n",
      "json5                     0.9.14\n",
      "jsonpointer               2.4\n",
      "jsonschema                4.20.0\n",
      "jsonschema-specifications 2023.12.1\n",
      "jupyter_client            8.6.0\n",
      "jupyter_core              5.7.1\n",
      "jupyter-events            0.9.0\n",
      "jupyter-lsp               2.2.1\n",
      "jupyter_server            2.12.4\n",
      "jupyter_server_terminals  0.5.1\n",
      "jupyterlab                4.0.10\n",
      "jupyterlab_pygments       0.3.0\n",
      "jupyterlab_server         2.25.2\n",
      "jupyterlab-widgets        3.0.9\n",
      "markdown-it-py            3.0.0\n",
      "MarkupSafe                2.1.3\n",
      "matplotlib-inline         0.1.6\n",
      "mdurl                     0.1.2\n",
      "mistune                   3.0.2\n",
      "mpmath                    1.3.0\n",
      "multidict                 6.0.4\n",
      "multiprocess              0.70.15\n",
      "nbclient                  0.9.0\n",
      "nbconvert                 7.14.1\n",
      "nbformat                  5.9.2\n",
      "nest-asyncio              1.5.9\n",
      "networkx                  3.2.1\n",
      "notebook_shim             0.2.3\n",
      "numpy                     1.26.3\n",
      "nvidia-cublas-cu12        12.1.3.1\n",
      "nvidia-cuda-cupti-cu12    12.1.105\n",
      "nvidia-cuda-nvrtc-cu12    12.1.105\n",
      "nvidia-cuda-runtime-cu12  12.1.105\n",
      "nvidia-cudnn-cu12         8.9.2.26\n",
      "nvidia-cufft-cu12         11.0.2.54\n",
      "nvidia-curand-cu12        10.3.2.106\n",
      "nvidia-cusolver-cu12      11.4.5.107\n",
      "nvidia-cusparse-cu12      12.1.0.106\n",
      "nvidia-nccl-cu12          2.18.1\n",
      "nvidia-nvjitlink-cu12     12.3.101\n",
      "nvidia-nvtx-cu12          12.1.105\n",
      "overrides                 7.4.0\n",
      "packaging                 23.2\n",
      "pandas                    2.1.4\n",
      "pandocfilters             1.5.0\n",
      "parso                     0.8.3\n",
      "peft                      0.7.1\n",
      "pexpect                   4.9.0\n",
      "pfzy                      0.3.4\n",
      "pip                       23.0.1\n",
      "platformdirs              4.1.0\n",
      "prometheus-client         0.19.0\n",
      "prompt-toolkit            3.0.43\n",
      "protobuf                  4.25.2\n",
      "psutil                    5.9.7\n",
      "ptyprocess                0.7.0\n",
      "pure-eval                 0.2.2\n",
      "pyarrow                   14.0.2\n",
      "pyarrow-hotfix            0.6\n",
      "pycparser                 2.21\n",
      "Pygments                  2.17.2\n",
      "python-dateutil           2.8.2\n",
      "python-json-logger        2.0.7\n",
      "pytz                      2023.3.post1\n",
      "PyYAML                    6.0.1\n",
      "pyzmq                     25.1.2\n",
      "referencing               0.32.1\n",
      "regex                     2023.12.25\n",
      "requests                  2.31.0\n",
      "rfc3339-validator         0.1.4\n",
      "rfc3986-validator         0.1.1\n",
      "rich                      13.7.0\n",
      "rpds-py                   0.17.1\n",
      "safetensors               0.4.1\n",
      "scipy                     1.11.4\n",
      "Send2Trash                1.8.2\n",
      "sentry-sdk                1.39.2\n",
      "setproctitle              1.3.3\n",
      "setuptools                65.5.0\n",
      "shtab                     1.6.5\n",
      "six                       1.16.0\n",
      "smmap                     5.0.1\n",
      "sniffio                   1.3.0\n",
      "soupsieve                 2.5\n",
      "stack-data                0.6.3\n",
      "sympy                     1.12\n",
      "terminado                 0.18.0\n",
      "tinycss2                  1.2.1\n",
      "tokenizers                0.15.0\n",
      "tomli                     2.0.1\n",
      "torch                     2.1.2\n",
      "tornado                   6.4\n",
      "tqdm                      4.66.1\n",
      "traitlets                 5.14.1\n",
      "transformers              4.38.0.dev0\n",
      "triton                    2.1.0\n",
      "trl                       0.7.9\n",
      "types-python-dateutil     2.8.19.20240106\n",
      "typing_extensions         4.9.0\n",
      "tyro                      0.6.4\n",
      "tzdata                    2023.4\n",
      "uri-template              1.3.0\n",
      "urllib3                   2.1.0\n",
      "wandb                     0.16.2\n",
      "wcwidth                   0.2.13\n",
      "webcolors                 1.13\n",
      "webencodings              0.5.1\n",
      "websocket-client          1.7.0\n",
      "wheel                     0.42.0\n",
      "widgetsnbextension        4.0.9\n",
      "xxhash                    3.4.1\n",
      "yarl                      1.9.4\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# login outside of jupyter notebook\n",
    "\n",
    "# !huggingface-cli whoami\n",
    "\n",
    "# import wandb\n",
    "# wandb.login()\n",
    "\n",
    "# !pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "295cf79c-b3db-48d5-94e0-26832de24979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe2db4f59abe47acaf9ae730b6ea2547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> [INST] What is your favourite condiment? [/INST]\n",
      "\n",
      "I'm not sure if this is a condiment, but I love ketchup. I'm not sure why, but I love it. I'm not a big fan of mustard, but I do like it on hot dogs. I'm not a big fan of mayonnaise, but I do like it on sandwiches. I'm not a big fan of relish, but I do like it on hot dogs. I'm not a big fan of pickles, but I do like them on sandwiches. I'm not a big fan of olives, but I do like them on pizza. I'm not a big fan of cheese, but I do like it on pizza. I'm not a big fan of tomatoes, but I do like them on pizza. I'm not a big fan of onions, but I do like them on pizza. I'm not a big fan of peppers, but I do like them on pizza. I'm not a big fan of mushrooms, but I do like them on pizza. I'm not a big fan of sausage, but I do like it on pizza. I'm not a big fan\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "model_name = \"mistralai/Mistral-7B-v0.1\"\n",
    "# model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"mistralai/Mistral-7B-v0.1\",\n",
    "    padding_side=\"left\", # set as left for mistral, right for llama2\n",
    "    add_eos_token=True,\n",
    "    add_bos_token=True,\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "\n",
    "inf_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What is your favourite condiment?\"},\n",
    "]\n",
    "encodeds = tokenizer.apply_chat_template(messages, return_tensors=\"pt\")\n",
    "\n",
    "device = \"cuda\"\n",
    "model_inputs = encodeds.to(device)\n",
    "\n",
    "generated_ids = inf_model.generate(model_inputs, max_new_tokens=256, pad_token_id=tokenizer.pad_token_id)\n",
    "decoded = tokenizer.batch_decode(generated_ids)\n",
    "print(decoded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2d56bf5-b1f2-430a-bee4-36b47cfbac23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test case: 0\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how can I jump higherм\n",
      "\n",
      "## How to jump higher\n",
      "\n",
      "Jumping is a skill that is used in many sports, such as basketball, volleyball, and track and field. It is also a skill that can be improved with practice. There are a few things that you can do to improve your jumping ability.\n",
      "\n",
      "One thing that you can do is to practice jumping as often as possible. This will help you to improve your coordination and your ability to jump higher. You can also try to jump as high as possible when you are practicing. This will help you to improve your jumping ability.\n",
      "\n",
      "Another thing that you can do is to practice jumping with a partner. This will help you to improve your coordination and your ability to jump higher. You can also try to jump as high as possible when you are practicing with a partner. This will help you to improve your jumping ability.\n",
      "\n",
      "You can also try to jump as high as possible when you are practicing with a partner. This will help you to improve your jumping ability.\n",
      "\n",
      "## How\n",
      "\n",
      "test case: 1\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how to dunk?й 2020\n",
      "\n",
      "# How to Dunk a Basketball: 10 Steps (with Pictures)\n",
      "\n",
      "## How to Dunk a Basketball: 10 Steps (with Pictures)\n",
      "\n",
      "How to Dunk a Basketball: 10 Steps (with Pictures)\n",
      "\n",
      "## How to Dunk a Basketball: 10 Steps (with Pictures)\n",
      "\n",
      "How to Dunk a Basketball: 10 Steps (with Pictures)\n",
      "\n",
      "## How to Dunk a Basketball: 10 Steps (with Pictures)\n",
      "\n",
      "How to Dunk a Basketball: 10 Steps (with Pictures)\n",
      "\n",
      "## How to Dunk a Basketball: 10 Steps (with Pictures)\n",
      "\n",
      "How to Dunk a Basketball: 10 Steps (with Pictures)\n",
      "\n",
      "## How to Dunk a Basketball: 10 Steps (with Pictures)\n",
      "\n",
      "How to Dunk a Basketball: 10 Ste\n",
      "\n",
      "test case: 2\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are barefoot shoots actually beneficial? 2019-05-15T15:55:00.000Z\n",
      "\n",
      "# are barefoot shoots actually beneficial?\n",
      "\n",
      "2019-05-15T15:55:00.000Z\n",
      "\n",
      "I've been reading a lot about barefoot shoots and how they are supposed to be beneficial. I've also read that they are not beneficial and can actually be harmful. I've also read that they are beneficial but only if you have a certain type of soil. I've also read that they are beneficial but only if you have a certain type of soil and a certain type of grass. I've also read that they are beneficial but only if you have a certain type of soil and a certain type of grass and a certain type of grass and a certain type of grass and a certain type of grass and a certain type of grass and a certain type of grass and a certain type of grass and a certain type of grass and a\n",
      "\n",
      "test case: 3\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what are the most important factors to becoming an elite athlete?мппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппппп\n",
      "\n",
      "test case: 4\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what are the core principles behind nutrition?м\n",
      "\n",
      "The core principles behind nutrition are:\n",
      "\n",
      "1. Eat a variety of foods from all the food groups.\n",
      "2. Eat a variety of foods within each food group.\n",
      "3. Eat the right amount of food to maintain a healthy weight.\n",
      "4. Eat the right amount of food to maintain a healthy weight.\n",
      "5. Eat the right amount of food to maintain a healthy weight.\n",
      "6. Eat the right amount of food to maintain a healthy weight.\n",
      "7. Eat the right amount of food to maintain a healthy weight.\n",
      "8. Eat the right amount of food to maintain a healthy weight.\n",
      "9. Eat the right amount of food to maintain a healthy weight.\n",
      "10. Eat the right amount of food to maintain a healthy weight.\n",
      "11. Eat the right amount of food to maintain a healthy weight.\n",
      "12. Eat the right amount of food to maintain a healthy weight.\n",
      "13. Eat the right amount of food to maintain\n",
      "\n",
      "test case: 5\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how do i lose weight while gaining muscleм\n",
      "\n",
      "# how do i lose weight while gaining muscle\n",
      "\n",
      "## How to Lose Weight While Gaining Muscle\n",
      "\n",
      "If you’re trying to lose weight while gaining muscle, you’re in for a challenge. It’s not easy to do both at the same time, but it is possible. Here are some tips to help you lose weight while gaining muscle.\n",
      "\n",
      "### 1. Eat a balanced diet\n",
      "\n",
      "Eating a balanced diet is essential for losing weight and gaining muscle. You need to make sure you’re getting enough protein, carbohydrates, and fats. Protein is essential for building muscle, carbohydrates are essential for energy, and fats are essential for hormone production.\n",
      "\n",
      "### 2. Lift weights\n",
      "\n",
      "Lifting weights is essential for gaining muscle. You need to make sure you’re lifting weights that are challenging enough to cause muscle growth. You also need to make sure you’re lifting weights that are heavy enough to cause muscle growth.\n",
      "\n",
      "\n",
      "\n",
      "test case: 6\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how do i get more energy?мд\n",
      "\n",
      "# how do i get more energy?\n",
      "\n",
      "## 1. Eat a healthy diet\n",
      "\n",
      "Eating a healthy diet is one of the best ways to get more energy. A healthy diet includes plenty of fruits, vegetables, whole grains, and lean protein. It also includes healthy fats, such as those found in nuts, seeds, and avocados.\n",
      "\n",
      "A healthy diet can help you feel more energized by providing your body with the nutrients it needs to function properly. It can also help you maintain a healthy weight, which can help you feel more energetic.\n",
      "\n",
      "If you’re looking to increase your energy levels, start by eating a healthy diet. Eating a variety of nutrient-rich foods will help you feel your best.\n",
      "\n",
      "## 2. Get enough sleep\n",
      "\n",
      "Getting enough sleep is one of the most important things you can do to increase your energy levels. When you’re well-rested, you’re able to think more clearly and make better decisions.\n",
      "\n",
      "test case: 7\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are plant based diets beneficial for better health? 2019\n",
      "\n",
      "# Are Plant Based Diets Beneficial for Better Health?\n",
      "\n",
      "## Are Plant Based Diets Beneficial for Better Health?\n",
      "\n",
      "Are Plant Based Diets Beneficial for Better Health?\n",
      "\n",
      "Plant based diets are becoming more and more popular. They are also known as vegan diets. They are diets that are based on plant foods. They are diets that are free of animal products. They are diets that are free of meat, fish, poultry, eggs, and dairy products.\n",
      "\n",
      "Plant based diets are becoming more and more popular. They are also known as vegan diets. They are diets that are based on plant foods. They are diets that are free of animal products. They are diets that are free of meat, fish, poultry, eggs, and dairy products.\n",
      "\n",
      "Plant based diets are becoming more and more popular. They are also known as vegan diets. They are diets that are based on\n",
      "\n",
      "test case: 8\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what are some quick wins to becoming a better athlete?м\n",
      "\n",
      "1 Like\n",
      "\n",
      "I’m not sure what you mean by “quick wins” but I’ll give you some advice that I’ve learned over the years.\n",
      "\n",
      "1. Be consistent.\n",
      "2. Be patient.\n",
      "3. Be humble.\n",
      "4. Be coachable.\n",
      "5. Be a good teammate.\n",
      "6. Be a good person.\n",
      "\n",
      "1 Like\n",
      "\n",
      "I’m not sure what you mean by “quick wins” but I’ll give you some advice that I’ve learned over the years.\n",
      "\n",
      "1. Be consistent.\n",
      "2. Be patient.\n",
      "3. Be humble.\n",
      "4. Be coachable.\n",
      "5. Be a good teammate.\n",
      "6. Be a good person.\n",
      "\n",
      "1 Like\n",
      "\n",
      "I’m not sure what you mean by “quick wins” but I’ll give you some advice that I’ve learned over the years.\n",
      "\n",
      "1. Be consistent.\n",
      "2. Be patient.\n",
      "3. Be humble\n",
      "\n",
      "test case: 9\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "does contrast therapy (ice bath and hot sauna) actually work? 2020\n",
      "\n",
      "# Does contrast therapy (ice bath and hot sauna) actually work?\n",
      "\n",
      "Does contrast therapy (ice bath and hot sauna) actually work?\n",
      "\n",
      "Ice baths and hot saunas are a popular recovery method used by athletes and fitness enthusiasts.\n",
      "\n",
      "The idea is that alternating between hot and cold temperatures can help reduce muscle soreness and improve recovery.\n",
      "\n",
      "This article explains how contrast therapy works and whether it’s effective.\n",
      "\n",
      "Contrast therapy is a recovery method that involves alternating between hot and cold temperatures.\n",
      "\n",
      "It’s also known as contrast water therapy, contrast hydrotherapy, contrast bathing, contrast showers, contrast baths, contrast bathing, contrast therapy, contrast water therapy, contrast hydrotherapy, contrast bathing, contrast baths, contrast bathing, contrast baths, contrast bathing, contrast baths, contrast bathing, contrast baths, contrast bathing, contrast baths, contrast bathing, contrast baths, contrast bath\n",
      "\n",
      "test case: 10\n",
      "cuda\n",
      "how exercises should I focus on at the gym to improve my basketball performance?м\n",
      "\n",
      "I’m 16 years old and I’m 6’2. I’m not the best basketball player but I’m not the worst either. I’m not the fastest or the strongest but I’m not the slowest or the weakest either. I’m not the best shooter but I’m not the worst either. I’m not the best dribbler but I’m not the worst either. I’m not the best passer but I’m not the worst either. I’m not the best defender but I’m not the worst either. I’m not the best rebounder but I’m not the worst either. I’m not the best at anything but I’m not the worst either. I’m just average at everything. I’m not the best basketball player but I’m not the worst either. I’m not the best at anything but I’m not the worst either. I’m just average at everything. I’\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_set = [\"how can I jump higher\",\"how to dunk?\",\"are barefoot shoots actually beneficial?\",\"what are the most important factors to becoming an elite athlete?\",\n",
    "\"what are the core principles behind nutrition?\",\n",
    "\"how do i lose weight while gaining muscle\",\n",
    "\"how do i get more energy?\",\n",
    "\"are plant based diets beneficial for better health?\",\n",
    "\"what are some quick wins to becoming a better athlete?\",\n",
    "\"does contrast therapy (ice bath and hot sauna) actually work?\",\n",
    "\"how exercises should I focus on at the gym to improve my basketball performance?\"]\n",
    "\n",
    "for i, prompt in enumerate(test_set):\n",
    "    print(\"test case:\", i)\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(device)\n",
    "    tokenizer.padding_side = \"left\"\n",
    "    model_input = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    _ = inf_model.eval()\n",
    "    with torch.no_grad():\n",
    "      out = inf_model.generate(**model_input, max_new_tokens=216)\n",
    "    \n",
    "    print(tokenizer.decode(out[0], skip_special_tokens=True))\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "42475479-4008-4a60-85b2-4f55d9b3213f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5905577472"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Empty VRAM\n",
    "# del model_inputs\n",
    "# del inf_model\n",
    "# del base_model_reload\n",
    "# del peft_model\n",
    "# del model_input\n",
    "\n",
    "import gc\n",
    "gc.collect()\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ecbfc85f-ecfc-486c-a249-0c0a0870530f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jan 22 09:11:41 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.146.02             Driver Version: 535.146.02   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A10G                    Off | 00000000:00:1E.0 Off |                    0 |\n",
      "|  0%   25C    P0              57W / 300W |   6870MiB / 23028MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "import locale\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cffe8500-7f5f-4fa9-8718-a855ca3e1d34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:t0nvz4j5) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">stilted-meadow-2</strong> at: <a href='https://wandb.ai/ongjjbrandon/ft-ft/runs/t0nvz4j5' target=\"_blank\">https://wandb.ai/ongjjbrandon/ft-ft/runs/t0nvz4j5</a><br/> View job at <a href='https://wandb.ai/ongjjbrandon/ft-ft/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEzMjU2ODYzMw==/version_details/v0' target=\"_blank\">https://wandb.ai/ongjjbrandon/ft-ft/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEzMjU2ODYzMw==/version_details/v0</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240122_090002-t0nvz4j5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:t0nvz4j5). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caf30107980a41cb888c3f7d29831fd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112219877799766, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/ft/wandb/run-20240122_090218-b00ivv6k</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ongjjbrandon/ft-ft/runs/b00ivv6k' target=\"_blank\">sweet-snowball-3</a></strong> to <a href='https://wandb.ai/ongjjbrandon/ft-ft' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ongjjbrandon/ft-ft' target=\"_blank\">https://wandb.ai/ongjjbrandon/ft-ft</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ongjjbrandon/ft-ft/runs/b00ivv6k' target=\"_blank\">https://wandb.ai/ongjjbrandon/ft-ft/runs/b00ivv6k</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact model-e16vcuhd:v0, 1640.60MB. 8 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   8 of 8 files downloaded.  \n",
      "Done. 0:0:19.1\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "run = wandb.init()\n",
    "artifact = run.use_artifact('ongjjbrandon/mistral-pjf-f2-v2/model-e16vcuhd:v0', type='model')\n",
    "artifact_dir = artifact.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4583d705-de6b-4f30-851f-3708ba67c64f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cabd520eb4e84b068122571c1144a0b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from peft import PeftModel\n",
    "base_model_reload = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name, low_cpu_mem_usage=True,\n",
    "    return_dict=True,torch_dtype=torch.bfloat16,\n",
    "    device_map= {\"\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ae5c884a-cb2f-4965-a2aa-818d55e2e227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a0e583af9ce4fc896b46079875033ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for MistralForCausalLM:\n\tsize mismatch for model.embed_tokens.modules_to_save.default.weight: copying a param with shape torch.Size([32002, 4096]) from checkpoint, the shape in current model is torch.Size([32000, 4096]).\n\tsize mismatch for lm_head.modules_to_save.default.weight: copying a param with shape torch.Size([32002, 4096]) from checkpoint, the shape in current model is torch.Size([32000, 4096]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# peft_model = PeftModel.from_pretrained(base_model_reload, \"./artifacts/model-e16vcuhd:v0\")\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m inf_model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./artifacts/model-e16vcuhd:v0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbnb_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:566\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    565\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 566\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    572\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/transformers/modeling_utils.py:3933\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3930\u001b[0m     model \u001b[38;5;241m=\u001b[39m quantizer\u001b[38;5;241m.\u001b[39mpost_init_model(model)\n\u001b[1;32m   3932\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _adapter_model_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 3933\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_adapter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3934\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_adapter_model_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3935\u001b[0m \u001b[43m        \u001b[49m\u001b[43madapter_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madapter_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3936\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3937\u001b[0m \u001b[43m        \u001b[49m\u001b[43madapter_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madapter_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3938\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3940\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_loading_info:\n\u001b[1;32m   3941\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m loading_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/transformers/integrations/peft.py:206\u001b[0m, in \u001b[0;36mPeftAdapterMixin.load_adapter\u001b[0;34m(self, peft_model_id, adapter_name, revision, token, device_map, max_memory, offload_folder, offload_index, peft_config, adapter_state_dict, adapter_kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m     processed_adapter_state_dict[new_key] \u001b[38;5;241m=\u001b[39m value\n\u001b[1;32m    205\u001b[0m \u001b[38;5;66;03m# Load state dict\u001b[39;00m\n\u001b[0;32m--> 206\u001b[0m incompatible_keys \u001b[38;5;241m=\u001b[39m \u001b[43mset_peft_model_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessed_adapter_state_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madapter_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m incompatible_keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;66;03m# check only for unexpected keys\u001b[39;00m\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(incompatible_keys, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munexpected_keys\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(incompatible_keys\u001b[38;5;241m.\u001b[39munexpected_keys) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/peft/utils/save_and_load.py:201\u001b[0m, in \u001b[0;36mset_peft_model_state_dict\u001b[0;34m(model, peft_model_state_dict, adapter_name)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n\u001b[0;32m--> 201\u001b[0m load_result \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpeft_model_state_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mis_prompt_learning:\n\u001b[1;32m    203\u001b[0m     model\u001b[38;5;241m.\u001b[39mprompt_encoder[adapter_name]\u001b[38;5;241m.\u001b[39membedding\u001b[38;5;241m.\u001b[39mload_state_dict(\n\u001b[1;32m    204\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m\"\u001b[39m: peft_model_state_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt_embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m]}, strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    205\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/torch/nn/modules/module.py:2152\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2147\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2148\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2149\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2152\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2153\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for MistralForCausalLM:\n\tsize mismatch for model.embed_tokens.modules_to_save.default.weight: copying a param with shape torch.Size([32002, 4096]) from checkpoint, the shape in current model is torch.Size([32000, 4096]).\n\tsize mismatch for lm_head.modules_to_save.default.weight: copying a param with shape torch.Size([32002, 4096]) from checkpoint, the shape in current model is torch.Size([32000, 4096])."
     ]
    }
   ],
   "source": [
    "# peft_model = PeftModel.from_pretrained(base_model_reload, \"./artifacts/model-e16vcuhd:v0\")\n",
    "inf_model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"./artifacts/model-e16vcuhd:v0\",\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdaf4d1-62ee-4d60-bdc5-067528c4b3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream(user_prompt):\n",
    "    runtimeFlag = \"cuda:0\"\n",
    "    system_prompt = 'The conversation between Human and AI named PaulGPT\\n'\n",
    "    B_INST, E_INST = \"[INST]\", \"[/INST]\"\n",
    "\n",
    "    prompt = f\"{system_prompt}{B_INST}{user_prompt.strip()}\\n{E_INST}\"\n",
    "\n",
    "    inputs = tokenizer([prompt], return_tensors=\"pt\").to(runtimeFlag)\n",
    "\n",
    "    streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)\n",
    "\n",
    "    _ = inf_model.generate(**inputs, streamer=streamer, max_new_tokens=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abdd4f7-9244-45a5-867d-153f2cb9b582",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream(\"what is newtons 2rd law and its formula\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cccd23-7fe3-441a-9bd8-a06293b20fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = [\"how can I jump higher\",\"how to dunk?\",\"are barefoot shoots actually beneficial?\",\"what are the most important factors to becoming an elite athlete?\",\n",
    "\"what are the core principles behind nutrition?\",\n",
    "\"how do i lose weight while gaining muscle\",\n",
    "\"how do i get more energy?\",\n",
    "\"are plant based diets beneficial for better health?\",\n",
    "\"what are some quick wins to becoming a better athlete?\",\n",
    "\"does contrast therapy (ice bath and hot sauna) actually work?\",\n",
    "\"how exercises should I focus on at the gym to improve my basketball performance?\"]\n",
    "\n",
    "for i, prompt in enumerate(test_set):\n",
    "    print(\"test case:\", i+1)\n",
    "    stream(prompt)\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad84b34a-1c5e-4172-9220-87e66f236862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear the memory footprint\n",
    "del model, trainer\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Reload the base model\n",
    "base_model_reload = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model, low_cpu_mem_usage=True,\n",
    "    return_dict=True,torch_dtype=torch.bfloat16,\n",
    "    device_map= {\"\": 0})\n",
    "model = PeftModel.from_pretrained(base_model_reload, new_model)\n",
    "model = model.merge_and_unload()\n",
    "\n",
    "# Reload tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb087f7-3dd3-4641-9638-5ab27d889579",
   "metadata": {},
   "outputs": [],
   "source": [
    "#push the model to hub\n",
    "!huggingface-cli login\n",
    "model.push_to_hub(new_model, use_temp_dir=False)\n",
    "tokenizer.push_to_hub(new_model, use_temp_dir=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c188193a-2938-4884-af75-fdc7873d473a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is a neural network??\n",
      " Hinweis: This answer is a simplified explanation of a neural network and its components. For a more detailed understanding, I recommend checking out online resources or taking a course on machine learning.\n",
      "\n",
      "A neural network is a complex system of interconnected nodes (also called neurons) that work together to perform a specific task, such as image recognition, language translation, or decision-making. The nodes are arranged in layers, and each layer processes the input data in a different way.\n",
      "\n",
      "The\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What is a neural network??\"\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_input = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "_ = model.eval()\n",
    "with torch.no_grad():\n",
    "    out = peft_model.generate(**model_input, max_new_tokens=100)\n",
    "\n",
    "print(tokenizer.decode(out[0], skip_special_tokens=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a3c2e640-8a5a-474a-9a63-f29706436910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "how can I jump higher in basketball?\n",
      " hopefully, this will help you improve your vertical jump and become a better basketball player.\n",
      "Here are some tips that can help you jump higher in basketball:\n",
      "1. Practice proper jumping technique: Make sure you are using proper jumping technique when trying to jump higher. This includes keeping your knees bent, your body loose, and your arms in the correct position.\n",
      "2. Incorporate plyometric exercises into your workout routine: Plyometric exercises, such as jump squats and box jumps, can help improve your explosiveness and power, which can translate to a higher vertical jump.\n",
      "3. Focus on core and leg strength: Having a strong core and legs can help you generate more power when jumping. Incorporate exercises like squats, lunges, and planks into your workout routine to improve your core and leg strength.\n",
      "4. Use resistance bands or a jump rope to improve your explosiveness: Resistance bands or a jump rope\n",
      "\n",
      "cuda\n",
      "how to dunk?\n",
      " geprüft�?\n",
      "dunking is a skill that requires practice and patience. Here are some tips to help you improve your dunking ability:\n",
      "1. Start with basic jumping and landing techniques: Before you can dunk, you need to master the basics of jumping and landing. Practice jumping up and down from a standstill, and work on landing softly on both feet.\n",
      "2. Work on your vertical jump: The higher you can jump, the easier it will be to dunk. You can improve your vertical jump by doing plyometric exercises such as box jumps, depth jumps, and calf raises.\n",
      "3. Practice dunking with different levels of difficulty: Start with easy dunks and gradually work your way up to more challenging ones. Practice dunking with different levels of speed and power to improve your control and accuracy.\n",
      "4. Focus on your footwork: Good footwork is essential for dunking. Practice shuffling,\n",
      "\n",
      "cuda\n",
      "are barefoot shoots actually beneficial?\n",
      " nobody likes to walk barefoot, especially in a public place. but there are some benefits to going without shoes. here are some reasons why barefoot shoots are actually beneficial:\n",
      "\n",
      "1. Improved balance and proprioception: When you're barefoot, you're able to feel the ground beneath you more clearly, which can help you develop better balance and proprioception (your body's ability to sense its position in space).\n",
      "\n",
      "2. Increased sensory input: Going barefoot allows your feet to receive more sensory input from the ground, which can help improve your overall sense of balance and coordination.\n",
      "\n",
      "3. Better posture: When you're barefoot, you're more likely to stand up straight and engage your core muscles, which can help improve your posture and reduce the risk of back pain.\n",
      "\n",
      "4. Stronger foot muscles: Going barefoot can help strengthen the muscles in your feet, which can improve your overall foot health\n",
      "\n",
      "cuda\n",
      "what are the most important factors to becoming an elite athlete?\n",
      " Hinweis: This is a subjective question, and the answer may vary depending on the sport, individual, and personal perspective. However, here are some common factors that are often cited as important for becoming an elite athlete:\n",
      "\n",
      "1. Natural talent: While hard work and dedication are essential, having a natural aptitude for the sport can give an athlete a significant advantage.\n",
      "2. Training and practice: Consistent and focused training is critical for improving performance and achieving elite status. This includes both physical practice and mental preparation.\n",
      "3. Mental toughness: The ability to perform under pressure and maintain a positive attitude in the face of adversity is essential for elite athletes.\n",
      "4. Nutrition and recovery: Proper nutrition and recovery strategies are crucial for optimal physical performance and preventing injury.\n",
      "5. Sleep and rest: Adequate sleep and rest are essential for physical and mental recovery, and can greatly impact athletic performance.\n",
      "6. Co\n",
      "\n",
      "cuda\n",
      "what are the core principles behind nutrition?\n",
      " everyone has different nutritional needs and requirements, but there are some core principles that apply to everyone. these principles can help guide your nutrition decisions and ensure you're getting the nutrients you need to stay healthy. here are the core principles of nutrition: 1. balance: the key to good nutrition is balance. this means consuming a variety of foods from all food groups in the right proportions. 2. variety: a diverse diet is essential for good health. aim to eat a wide variety of foods, including fruits, vegetables, whole grains, lean proteins, and healthy fats. 3. moderation: everything in moderation is the motto of good nutrition. this means not consuming too much of any one food, but rather enjoying a variety of foods in appropriate portions. 4. quality: the quality of your food matters just as much as the quantity. choose whole, unprocessed foods as much as possible\n",
      "\n",
      "cuda\n",
      "how do i lose weight while gaining muscle\n",
      " everybody wants to lose weight and gain muscle, but it can be challenging to do both at the same time. Here are some tips to help you lose weight while gaining muscle: 1. Eat enough protein: Protein is essential for muscle growth, so make sure you're consuming enough protein-rich foods such as chicken, fish, beef, lamb, eggs, dairy products, and legumes. 2. Incorporate strength training: Resistance exercises such as weightlifting, bodyweight exercises, and resistance band exercises can help you build muscle. Aim to do strength training exercises at least two to three times a week. 3. Don't forget cardio: While strength training is important for building muscle, cardio exercises such as running, cycling, and swimming can help you burn calories and lose weight. Aim to do at least 150 minutes of moderate-intensity card\n",
      "\n",
      "cuda\n",
      "how do i get more energy?\n",
      " Unterscheidung zwischen \"Energie\" und \"Power\".\n",
      "\n",
      "Here are some tips to help you increase your energy levels:\n",
      "\n",
      "1. Exercise regularly: Exercise can help increase energy levels by boosting circulation, oxygenating the body, and releasing endorphins, which are natural mood elevators. Aim for at least 30 minutes of moderate-intensity exercise per day.\n",
      "2. Get enough sleep: Lack of sleep can lead to fatigue and decreased energy levels. Aim for 7-8 hours of sleep per night to help you feel rested and refreshed.\n",
      "3. Eat a balanced diet: A healthy diet that includes plenty of fruits, vegetables, whole grains, and lean protein can help support energy production. Avoid sugary and processed foods that can cause energy crashes.\n",
      "4. Stay hydrated: Dehydration can lead to fatigue and decreased energy levels. Aim for\n",
      "\n",
      "cuda\n",
      "are plant based diets beneficial for better health?\n",
      " nobody is arguing that a plant-based diet is not beneficial for health. In fact, a well-planned plant-based diet can provide numerous health benefits, including:\n",
      "\n",
      "1. Lower risk of heart disease: A plant-based diet has been shown to lower the risk of heart disease by reducing saturated fat intake and increasing fiber and antioxidant intake.\n",
      "\n",
      "2. Weight loss: Plant-based diets tend to be lower in calories and higher in fiber, which can help with weight loss and maintenance.\n",
      "\n",
      "3. Improved blood sugar control: Plant-based diets have been shown to improve insulin sensitivity and blood sugar control, which can help prevent or manage type 2 diabetes.\n",
      "\n",
      "4. Reduced inflammation: Plant-based diets are high in antioxidants and anti-inflammatory compounds, which can help reduce inflammation and improve overall health.\n",
      "\n",
      "5.\n",
      "\n",
      "cuda\n",
      "what are some quick wins to becoming a better athlete?\n",
      " everybody wants to be a better athlete, but sometimes it can be hard to know where to start. here are some quick wins to help you improve your performance on the field, court, or track:\n",
      "1. Get enough sleep: sleep is essential for athletes, as it allows your body to recover from the day's training and repair itself. aim for 7-9 hours of sleep each night to help you perform at your best.\n",
      "2. Stretch regularly: stretching can help improve your flexibility, range of motion, and reduce your risk of injury. aim to stretch for 10-15 minutes each day, focusing on your major muscle groups.\n",
      "3. Strength train: adding strength training to your routine can help improve your power, speed, and endurance. aim to do 2-3 strength training sessions each week, focusing on compound exercises like squats, deadlifts, and bench press.\n",
      "4. Practice mental toughness: mental toughness is\n",
      "\n",
      "cuda\n",
      "does contrast therapy (ice bath and hot sauna) actually work?\n",
      "ϊ mean, it's supposed to reduce inflammation and help with muscle recovery, but I'm not sure if it's just a placebo effect or if it's actually doing something.\n",
      "\n",
      "I've tried both ice baths and hot saunas, and I've noticed some benefits, but I'm not sure if it's just my mind playing tricks on me. I've read some studies that suggest that contrast therapy can be effective in reducing muscle soreness and improving recovery after exercise, but I'm not sure if those studies are reliable or if they're just cherry-picking the results that support their claims.\n",
      "\n",
      "I'm curious to know if anyone has any personal experience with contrast therapy, or if they know of any reputable studies that have looked into its effectiveness. I'm hoping to find some concrete evidence to support its claims, so I can make an informed decision about whether or not to continue using it.\n",
      "\n",
      "Thanks in advance for\n",
      "\n",
      "cuda\n",
      "how exercises should I focus on at the gym to improve my basketball performance?\n",
      " everybody has different fitness goals and needs, but here are some general tips for improving your basketball performance at the gym:\n",
      "\n",
      "1. Strength Training: Basketball is a highly explosive and powerful sport, so building strength through exercises like squats, deadlifts, and lunges is crucial for improving your performance. Focus on exercises that target your legs, core, and upper body, as these are the muscles you use most during gameplay.\n",
      "\n",
      "2. Plyometrics: Plyometric exercises, such as jump squats and box jumps, can help improve your vertical jump and explosiveness on the court. These exercises involve quick, powerful movements that mimic the movements you use during gameplay.\n",
      "\n",
      "3. Agility Training: Agility training, such as cone drills and ladder drills, can help improve your quickness and change-of-direction speed. These exercises can help you react faster to your opponents and make quick moves\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_set = [\"how can I jump higher\",\"how to dunk?\",\"are barefoot shoots actually beneficial?\",\"what are the most important factors to becoming an elite athlete?\",\n",
    "\"what are the core principles behind nutrition?\",\n",
    "\"how do i lose weight while gaining muscle\",\n",
    "\"how do i get more energy?\",\n",
    "\"are plant based diets beneficial for better health?\",\n",
    "\"what are some quick wins to becoming a better athlete?\",\n",
    "\"does contrast therapy (ice bath and hot sauna) actually work?\",\n",
    "\"how exercises should I focus on at the gym to improve my basketball performance?\"]\n",
    "\n",
    "for prompt in test_set:\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(device)\n",
    "    model_input = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    _ = peft_model.eval()\n",
    "    with torch.no_grad():\n",
    "      out = peft_model.generate(**model_input, max_new_tokens=216)\n",
    "    \n",
    "    print(tokenizer.decode(out[0], skip_special_tokens=True))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d6e6b461-7ad5-49e6-a239-712da07cea69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 3.87G/3.87G [01:29<00:00, 43.4MB/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/ogbrandt/llama2-7b-chat-pjf-instruction-tune/commit/ca1916e13da6832471b916005a8d28c405b2adfc', commit_message='Upload LlamaForCausalLM', commit_description='', oid='ca1916e13da6832471b916005a8d28c405b2adfc', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model_name = \"llama2-7b-chat-pjf-instruction-tune\"\n",
    "inf_model.push_to_hub(new_model_name)\n",
    "# tokenizer.push_to_hub(new_model, use_temp_dir=False, token=hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c747858d-3929-4ba0-bb38-19f9fbae882d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
